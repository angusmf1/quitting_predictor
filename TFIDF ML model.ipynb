{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e2b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "import scipy.sparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1527402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\AppData\\Local\\Temp\\ipykernel_11020\\1616235069.py:1: DtypeWarning: Columns (137,139,141,142,143,144,145,146,147,148,149) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('merged_df_full_profile.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('merged_df_full_profile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52be0ade",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81291\n"
     ]
    }
   ],
   "source": [
    "null_counts = df['Skills'].isnull().sum()\n",
    "\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b14aa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Linkedin_url', 'target', 'profile_url', 'First Nam', 'Middle Nam',\n",
      "       'Surnam', 'connections_x', 'Summary', 'Skills', 'title_1',\n",
      "       ...\n",
      "       'edu 9 dat', 'edu 9 degrees', 'edu 9 descriptio', 'edu 10 titl',\n",
      "       'edu 10 dat', 'edu 10 degrees', 'edu 10 descriptio', 'merged_degrees',\n",
      "       'merged_edu', 'highest_edu'],\n",
      "      dtype='object', length=153)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9047fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word_Count'] = df['Job_Description_1'].apply(lambda text: len(str(text).split()) if pd.notnull(text) else 0)\n",
    "median_word_count = df['Word_Count'].median()\n",
    "df['Word_Count'] = df['Word_Count'].replace(0, median_word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3265e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary_is_null'] = df['Job_Description_1'].isnull().astype(int)\n",
    "df['skills_is_null'] = df['Skills'].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1751575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    104217\n",
       "1     81291\n",
       "Name: skills_is_null, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['skills_is_null'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde24f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts\n",
      "profile_url               0\n",
      "Job_Description_1    119520\n",
      "Summary               56893\n",
      "Skills                81291\n",
      "Word_Count                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts_target = df[['profile_url','Job_Description_1', 'Summary', 'Skills', 'Word_Count']].isnull().sum()\n",
    "print(\"Null counts\")\n",
    "print(null_counts_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1af0e0",
   "metadata": {},
   "source": [
    "### Data Pre-processiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "311da979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Jainish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jainish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jainish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('omw-1.4')\n",
    "# Download stopwords and WordNet data from NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):  # Check if the text is null\n",
    "        return ''\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))  # Use set(stopwords) instead of `stopwords`\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    processed_text = \" \".join(tokens)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5279271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_skills(skills):\n",
    "    if pd.isnull(skills):  # Check if the skills are null\n",
    "        return ''\n",
    "\n",
    "    skills = skills.lower()  # Convert skills to lowercase\n",
    "\n",
    "    # Split the skills by commas\n",
    "    skill_list = skills.split(',')\n",
    "\n",
    "    # Process each individual skill\n",
    "    processed_skills = []\n",
    "    for skill in skill_list:\n",
    "        # Remove leading/trailing whitespace\n",
    "        skill = skill.strip()\n",
    "\n",
    "        # Replace space with underscore\n",
    "        skill = skill.replace(' ', '_')\n",
    "\n",
    "        # Remove special characters and numbers\n",
    "        skill = re.sub(r\"[^a-zA-Z]\", \" \", skill)\n",
    "\n",
    "        # Tokenize the skill\n",
    "        tokens = word_tokenize(skill)\n",
    "\n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "        # Lemmatize the tokens\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "        # Join the tokens back into a single string\n",
    "        processed_skill = \"_\".join(tokens)\n",
    "        processed_skills.append(processed_skill)\n",
    "\n",
    "    # Join the processed skills back into a single string\n",
    "    processed_text = \", \".join(processed_skills)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c54562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\AppData\\Local\\Temp\\ipykernel_11020\\3298440275.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['Job_Description_1'] = df_selected['Job_Description_1'].apply(preprocess_text)\n",
      "C:\\Users\\Jainish\\AppData\\Local\\Temp\\ipykernel_11020\\3298440275.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['Summary'] = df_selected['Summary'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "df_selected = df[['profile_url','Job_Description_1', 'Summary', 'Skills', 'Word_Count', 'summary_is_null', 'skills_is_null', 'target']]\n",
    "\n",
    "df_selected['Job_Description_1'] = df_selected['Job_Description_1'].apply(preprocess_text)\n",
    "df_selected['Summary'] = df_selected['Summary'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef5e6ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\AppData\\Local\\Temp\\ipykernel_11020\\1296174013.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['Skills'] = df_selected['Skills'].apply(preprocess_skills)\n"
     ]
    }
   ],
   "source": [
    "df_selected['Skills'] = df_selected['Skills'].apply(preprocess_skills)\n",
    "\n",
    "X = df_selected[['profile_url','Job_Description_1', 'Summary', 'Skills', 'Word_Count', 'summary_is_null', 'skills_is_null']]\n",
    "y = df_selected['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cc47855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer for Job_Description_1\n",
    "tfidf_job_desc = TfidfVectorizer(max_features=10,use_idf=False)\n",
    "X_job_desc_tfidf = tfidf_job_desc.fit_transform(X['Job_Description_1'])\n",
    "\n",
    "# Get the feature names for Job_Description_1 and modify them\n",
    "job_desc_feature_names = ['job_desc_' + name for name in tfidf_job_desc.get_feature_names_out()]\n",
    "\n",
    "# Create TF-IDF vectorizer for Summary\n",
    "tfidf_summary = TfidfVectorizer(max_features=10,use_idf=False)\n",
    "X_summary_tfidf = tfidf_summary.fit_transform(X['Summary'])\n",
    "\n",
    "# Get the feature names for Summary and modify them\n",
    "summary_feature_names = ['summary_' + name for name in tfidf_summary.get_feature_names_out()]\n",
    "\n",
    "# Create TF-IDF vectorizer for Skills\n",
    "tfidf_skills = TfidfVectorizer(max_features=10, use_idf=False)\n",
    "X_skills_tfidf = tfidf_skills.fit_transform(X['Skills'])\n",
    "skills_feature_names = ['skills_' + name for name in tfidf_skills.get_feature_names_out()]\n",
    "\n",
    "# Combine the TF-IDF features\n",
    "X_combined = pd.DataFrame.sparse.from_spmatrix(scipy.sparse.hstack([X_job_desc_tfidf, X_summary_tfidf, X_skills_tfidf]), columns=job_desc_feature_names + summary_feature_names + skills_feature_names)\n",
    "\n",
    "# Apply Variance Threshold Feature Selection on X_combined\n",
    "variance_threshold = VarianceThreshold(threshold=0.01)\n",
    "X_selected = variance_threshold.fit_transform(X_combined)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_feature_indices = variance_threshold.get_support(indices=True)\n",
    "selected_feature_names = [X_combined.columns[i] for i in selected_feature_indices]\n",
    "\n",
    "# Create a DataFrame with the selected features and Word_Count\n",
    "X_selected_df = X_combined[selected_feature_names].copy()\n",
    "X_selected_df['Word_Count'] = X['Word_Count']\n",
    "X_selected_df['summary_is_null'] = X['summary_is_null']\n",
    "X_selected_df['skills_is_null'] = X['skills_is_null']\n",
    "X_selected_df['profile_url'] = X['profile_url']\n",
    "\n",
    "\n",
    "X_selected_df.to_csv('text_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "702329ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected_df = X_selected_df.drop('profile_url', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9245d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_df, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f622977a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_desc_application</th>\n",
       "      <th>job_desc_data</th>\n",
       "      <th>job_desc_design</th>\n",
       "      <th>job_desc_development</th>\n",
       "      <th>job_desc_project</th>\n",
       "      <th>job_desc_service</th>\n",
       "      <th>job_desc_software</th>\n",
       "      <th>job_desc_system</th>\n",
       "      <th>job_desc_team</th>\n",
       "      <th>job_desc_using</th>\n",
       "      <th>...</th>\n",
       "      <th>skills_java</th>\n",
       "      <th>skills_javascript</th>\n",
       "      <th>skills_linux</th>\n",
       "      <th>skills_mysql</th>\n",
       "      <th>skills_python</th>\n",
       "      <th>skills_software_development</th>\n",
       "      <th>skills_sql</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>summary_is_null</th>\n",
       "      <th>skills_is_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_desc_application  job_desc_data  job_desc_design  job_desc_development  \\\n",
       "0                   0.0            0.0              0.0                   0.0   \n",
       "1                   0.0            0.0              0.0                   0.0   \n",
       "2                   0.0            0.0              0.0                   0.0   \n",
       "3                   0.0            0.0              0.0                   0.0   \n",
       "4                   0.0            0.0              0.0                   0.0   \n",
       "\n",
       "   job_desc_project  job_desc_service  job_desc_software  job_desc_system  \\\n",
       "0               0.0               0.0                0.0              0.0   \n",
       "1               0.0               0.0                0.0              0.0   \n",
       "2               0.0               1.0                0.0              0.0   \n",
       "3               0.0               0.0                0.0              0.0   \n",
       "4               0.0               0.0                0.0              0.0   \n",
       "\n",
       "   job_desc_team  job_desc_using  ...  skills_java  skills_javascript  \\\n",
       "0            0.0             0.0  ...     0.000000           0.000000   \n",
       "1            1.0             0.0  ...     0.000000           0.000000   \n",
       "2            0.0             0.0  ...     0.000000           0.000000   \n",
       "3            0.0             0.0  ...     0.000000           0.000000   \n",
       "4            0.0             0.0  ...     0.447214           0.447214   \n",
       "\n",
       "   skills_linux  skills_mysql  skills_python  skills_software_development  \\\n",
       "0      0.000000           0.0        0.00000                     1.000000   \n",
       "1      0.000000           0.0        0.00000                     0.707107   \n",
       "2      0.577350           0.0        0.57735                     0.577350   \n",
       "3      0.000000           0.0        0.00000                     0.000000   \n",
       "4      0.447214           0.0        0.00000                     0.000000   \n",
       "\n",
       "   skills_sql  Word_Count  summary_is_null  skills_is_null  \n",
       "0    0.000000           0                1               0  \n",
       "1    0.000000           4                0               0  \n",
       "2    0.000000         116                0               0  \n",
       "3    0.000000           0                1               1  \n",
       "4    0.447214           2                0               0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6379ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_desc_application', 'job_desc_data', 'job_desc_design',\n",
       "       'job_desc_development', 'job_desc_project', 'job_desc_service',\n",
       "       'job_desc_software', 'job_desc_system', 'job_desc_team',\n",
       "       'job_desc_using', 'summary_application', 'summary_data',\n",
       "       'summary_development', 'summary_experience', 'summary_software',\n",
       "       'summary_system', 'summary_team', 'summary_technology', 'summary_web',\n",
       "       'summary_year', 'skills_agile_methodology', 'skills_cs', 'skills_html',\n",
       "       'skills_java', 'skills_javascript', 'skills_linux', 'skills_mysql',\n",
       "       'skills_python', 'skills_software_development', 'skills_sql',\n",
       "       'Word_Count', 'summary_is_null', 'skills_is_null'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3597dcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    166810\n",
       "1     18698\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5e20585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9005\n",
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     41788\n",
      "           1       0.24      0.00      0.01      4589\n",
      "\n",
      "    accuracy                           0.90     46377\n",
      "   macro avg       0.57      0.50      0.48     46377\n",
      "weighted avg       0.84      0.90      0.85     46377\n",
      "\n",
      "LightGBM Accuracy: 0.9010\n",
      "\n",
      "LightGBM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     41788\n",
      "           1       0.00      0.00      0.00      4589\n",
      "\n",
      "    accuracy                           0.90     46377\n",
      "   macro avg       0.45      0.50      0.47     46377\n",
      "weighted avg       0.81      0.90      0.85     46377\n",
      "\n",
      "Multinomial Naive Bayes Accuracy: 0.8247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90     41788\n",
      "           1       0.15      0.16      0.16      4589\n",
      "\n",
      "    accuracy                           0.82     46377\n",
      "   macro avg       0.53      0.53      0.53     46377\n",
      "weighted avg       0.83      0.82      0.83     46377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Accuracy: 0.8908\n",
      "\n",
      "K-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     41788\n",
      "           1       0.12      0.02      0.03      4589\n",
      "\n",
      "    accuracy                           0.89     46377\n",
      "   macro avg       0.51      0.50      0.49     46377\n",
      "weighted avg       0.82      0.89      0.85     46377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.8450\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92     41788\n",
      "           1       0.13      0.10      0.11      4589\n",
      "\n",
      "    accuracy                           0.85     46377\n",
      "   macro avg       0.52      0.51      0.51     46377\n",
      "weighted avg       0.83      0.85      0.84     46377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.9011\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     41788\n",
      "           1       0.00      0.00      0.00      4589\n",
      "\n",
      "    accuracy                           0.90     46377\n",
      "   macro avg       0.45      0.50      0.47     46377\n",
      "weighted avg       0.81      0.90      0.85     46377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.9011\n",
      "\n",
      "AdaBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     41788\n",
      "           1       0.00      0.00      0.00      4589\n",
      "\n",
      "    accuracy                           0.90     46377\n",
      "   macro avg       0.45      0.50      0.47     46377\n",
      "weighted avg       0.81      0.90      0.85     46377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Generate classification report\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    print()\n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b0be7c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 2.0, 'fit_prior': True}\n",
      "Best Score: 0.8233391306619907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "# Create the classifier\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1611dbe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90     41788\n",
      "           1       0.15      0.16      0.16      4589\n",
      "\n",
      "    accuracy                           0.82     46377\n",
      "   macro avg       0.53      0.53      0.53     46377\n",
      "weighted avg       0.83      0.82      0.83     46377\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainish\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=2, fit_prior=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b61ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49616c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
